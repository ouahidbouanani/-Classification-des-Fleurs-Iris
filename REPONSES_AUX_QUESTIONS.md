# üìù R√©ponses aux Questions du Projet

## PARTIE 1 : Analyse Statistique Descriptive

### Question 1 : Quelles esp√®ces semblent surrepr√©sent√©es dans le dataset ?
**R√©ponse :** Aucune esp√®ce n'est surrepr√©sent√©e. Le dataset est parfaitement √©quilibr√© avec 50 observations pour chacune des 3 esp√®ces (setosa, versicolor, virginica).

### Question 2 : Existe-t-il des diff√©rences marqu√©es de taille entre les esp√®ces ?
**R√©ponse :** OUI, il existe des diff√©rences marqu√©es :
- **P√©tales** : Les setosa ont des p√©tales beaucoup plus petits (~1.5 cm) que les virginica (~5.5 cm)
- **S√©pales** : Diff√©rences moins marqu√©es mais pr√©sentes
- **Diff√©rence maximale** : ~4 cm pour la longueur des p√©tales

### Question 3 : Les p√©tales ou les s√©pales semblent-ils plus discriminants ?
**R√©ponse :** Les **P√âTALES** sont beaucoup plus discriminants.
- petal_length a un ratio variance inter/intra d'environ 119
- petal_width a un ratio d'environ 86
- Les s√©pales ont des ratios beaucoup plus faibles (~23 et ~15)

## PARTIE 2 : Visualisation des Donn√©es

### Question 1 : Quelles variables semblent fortement corr√©l√©es ?
**R√©ponse :**
- **petal_length et petal_width** : r ‚âà 0.963 (tr√®s forte corr√©lation)
- **petal_length et sepal_length** : r ‚âà 0.872 (forte corr√©lation)
- **sepal_width et sepal_length** : r ‚âà -0.118 (faible corr√©lation n√©gative)

### Question 2 : Existe-t-il des biais visuels √† prendre en compte ?
**R√©ponse :** NON, pas de biais √©vident :
- Distribution √©quilibr√©e des 3 esp√®ces
- Pas de valeurs aberrantes majeures
- Donn√©es bien structur√©es sans valeurs manquantes

### Question 3 : Quelles observations permettent de mieux distinguer les esp√®ces ?
**R√©ponse :**
- **Setosa** est tr√®s facilement s√©parable (p√©tales beaucoup plus petits)
- **Versicolor et Virginica** se chevauchent l√©g√®rement dans certaines dimensions
- Les **dimensions des p√©tales** (longueur et largeur) offrent la meilleure s√©paration

## PARTIE 3 : R√©gression

### Question 1 : Quels param√®tres influencent le plus la longueur des p√©tales ?
**R√©ponse :** Par ordre d'influence (corr√©lation) :
1. **petal_width** : r ‚âà 0.963 (influence tr√®s forte)
2. **sepal_length** : r ‚âà 0.872 (influence forte)
3. **sepal_width** : r ‚âà 0.818 (influence mod√©r√©e)

### Question 2 : Le mod√®le multiple am√©liore-t-il la pr√©diction ?
**R√©ponse :** OUI, significativement :
- Le R¬≤ du mod√®le multiple est sup√©rieur au mod√®le simple
- L'utilisation de plusieurs variables explicatives capte plus d'information
- Le RMSE diminue avec le mod√®le multiple

### Question 3 : Les hypoth√®ses de la r√©gression sont-elles respect√©es ?
**R√©ponse :** OUI, les hypoth√®ses sont g√©n√©ralement respect√©es :
- **Lin√©arit√©** : ‚úÖ Visible dans les graphiques de r√©gression
- **Normalit√© des r√©sidus** : ‚úÖ Test de Shapiro-Wilk avec p > 0.05
- **Homosc√©dasticit√©** : ‚úÖ Variance constante observ√©e
- **Moyenne des r√©sidus** : ‚úÖ Tr√®s proche de 0

## PARTIE 4 : Classification Supervis√©e

### Question 1 : Quelles esp√®ces sont les plus difficiles √† pr√©dire et pourquoi ?
**R√©ponse :**
- **Setosa** : La plus facile (100% de pr√©cision) - tr√®s distincte des autres
- **Versicolor** : Difficult√© mod√©r√©e - peut se confondre avec Virginica
- **Virginica** : Difficult√© mod√©r√©e - peut se confondre avec Versicolor
- **Raison** : Chevauchement partiel de Versicolor et Virginica dans l'espace des features

### Question 2 : Quelles variables sont les plus discriminantes pour la classification ?
**R√©ponse :** Selon l'importance des features (Random Forest) :
1. **petal_length** : Importance ~45%
2. **petal_width** : Importance ~42%
3. **sepal_length** : Importance ~9%
4. **sepal_width** : Importance ~4%

Les dimensions des p√©tales repr√©sentent ~87% du pouvoir discriminant !

### Question 3 : Quels indicateurs statistiques sont les plus pertinents pour le dataset Iris ?
**R√©ponse :**
- **Accuracy** : Excellente m√©trique (>95% pour tous les mod√®les test√©s)
- **F1-Score** : Pertinent car √©quilibre pr√©cision et recall
- **Matrice de confusion** : Permet d'identifier pr√©cis√©ment les confusions entre esp√®ces
- **Cross-validation** : Confirme la robustesse et la g√©n√©ralisation du mod√®le
- **Feature importance** : Identifie les variables critiques

## R√©sum√© Global

### Points Cl√©s du Projet
1. **Dataset √©quilibr√©** : Parfait pour classification supervis√©e
2. **P√©tales > S√©pales** : Variables les plus discriminantes
3. **Setosa distincte** : Facile √† classifier
4. **Versicolor/Virginica** : L√©g√®re confusion possible
5. **Accuracy >95%** : Excellent r√©sultat de classification

### Meilleurs Mod√®les
- **Random Forest** : G√©n√©ralement le meilleur (95-100%)
- **SVM** : Tr√®s bon √©galement
- **Logistic Regression** : Excellent pour ce probl√®me lin√©airement s√©parable

### Technologies Utilis√©es
- **Python 3.13.2**
- **MongoDB** : Stockage NoSQL optimis√©
- **scikit-learn** : Machine Learning
- **Streamlit** : Prototype interactif
- **UCI ML Repo / Kaggle** : Sources de donn√©es

---

**Date** : F√©vrier 2026
**Projet** : Classification des Fleurs Iris avec MongoDB
